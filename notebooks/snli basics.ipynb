{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91af82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fp_dataset_artifacts.utils import init_openai\n",
    "\n",
    "init_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4dfe4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3028ee07d3974fb5b4a4c25e22c32462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ad279f530840fa8887b5796d8e85d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/938 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset snli/plain_text (download: 90.17 MiB, generated: 65.51 MiB, post-processed: Unknown size, total: 155.68 MiB) to /home/x/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a26c1660e35478591973a531dcba1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3cda35514f479ba9e50cbe95abb24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1a70ac1d0641e18271191c457e77c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e134f0546f484aaeb6088e76dd52241e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset snli downloaded and prepared to /home/x/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a662f55f84739a763ff3f8089efa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 550152\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
    "\n",
    "data = load_dataset('snli')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23c6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5a6f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is training his horse for a competition.\n",
      "label: 1\n"
     ]
    }
   ],
   "source": [
    "# Create example\n",
    "\n",
    "def to_example(data, include_label=True):\n",
    "    sentences = []\n",
    "    \n",
    "    for feature in data.keys():                \n",
    "        text = data[feature]\n",
    "        \n",
    "        if feature == 'label' and not include_label:\n",
    "            text = ''\n",
    "        \n",
    "        sentence = f'{feature}: {text}'\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return '\\n'.join(sentences)\n",
    "\n",
    "example = to_example(data['train'][0])\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cfde67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc76350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the label is a number. Would the model perform better if we provided the string values instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eeead7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is training his horse for a competition.\n",
      "label: 1\n",
      "\n",
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is at a diner, ordering an omelette.\n",
      "label: 2\n",
      "\n",
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is outdoors, on a horse.\n",
      "label: 0\n"
     ]
    }
   ],
   "source": [
    "exs = '\\n\\n'.join([to_example(train[i]) for i in range(3)])\n",
    "print(exs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d371d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is training his horse for a competition.\n",
      "label: 1\n",
      "\n",
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is at a diner, ordering an omelette.\n",
      "label: 2\n",
      "\n",
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is outdoors, on a horse.\n",
      "label: 0\n",
      "\n",
      "premise: Children smiling and waving at camera\n",
      "hypothesis: There are children present\n",
      "label: \n"
     ]
    }
   ],
   "source": [
    "# Let's try making some classifications\n",
    "x = to_example(train[4], False)\n",
    "prompt = f'{exs}\\n\\n{x}'\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dc810bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-47FPqWHYsLC5bjuXOpNvA5Klgz1J2 at 0x7f76c87cd720> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1637632902,\n",
       "  \"id\": \"cmpl-47FPqWHYsLC5bjuXOpNvA5Klgz1J2\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the most powerful model with max_tokens=1 since we only need a single digit as output\n",
    "response = openai.Completion.create(\n",
    "  engine='davinci',\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=['\\n']\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06551c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-47FQhXNGUd7EaVfftmlB8f2GdDgx2 at 0x7f76c87cd090> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\npremise: Children smiling and waving at camera\\nhypothesis:\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1637632955,\n",
       "  \"id\": \"cmpl-47FQhXNGUd7EaVfftmlB8f2GdDgx2\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seems like that didn't work. We can try it again without those parameters.\n",
    "response = openai.Completion.create(\n",
    "  engine='davinci',\n",
    "  prompt=prompt,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0212746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is training his horse for a competition.\n",
      "label: neutral\n"
     ]
    }
   ],
   "source": [
    "# The model tries to predict the next premise and hypothesis by copying,\n",
    "# which is basically what's happening in the example.\n",
    "# Since it might be ignoring the numbers. Let's try to use the actual label and add more examples for safe measure.\n",
    "int2label = train.features['label'].int2str\n",
    "\n",
    "def to_example(data, include_label=True):\n",
    "    sentences = []\n",
    "    \n",
    "    for feature in data.keys():                \n",
    "        text = data[feature]\n",
    "        \n",
    "        if feature == 'label':\n",
    "            if not include_label:\n",
    "                text = ''\n",
    "            else:\n",
    "                text = int2label(text)\n",
    "            \n",
    "        sentence = f'{feature}: {text}'\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return '\\n'.join(sentences)\n",
    "\n",
    "example = to_example(train[0])\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99c1ae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is training his horse for a competition.\n",
      "label: neutral\n",
      "\n",
      "premise: An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\n",
      "hypothesis: A boy flips a burger.\n",
      "label: contradiction\n",
      "\n",
      "premise: A woman is walking across the street eating a banana, while a man is following with his briefcase.\n",
      "hypothesis: the woman is a seductress\n",
      "label: neutral\n",
      "\n",
      "premise: People on bicycles waiting at an intersection.\n",
      "hypothesis: There is a bike race happening right now.\n",
      "label: neutral\n",
      "\n",
      "premise: A foreign family is walking along a dirt path next to the water.\n",
      "hypothesis: A family of foreigners walks by the water.\n",
      "label: entailment\n",
      "\n",
      "premise: A guy performing a bicycle jump trick for an audience.\n",
      "hypothesis: tony hawk is performing a skating trick\n",
      "label: contradiction\n",
      "\n",
      "premise: Children smiling and waving at camera\n",
      "hypothesis: There are children present\n",
      "label: \n"
     ]
    }
   ],
   "source": [
    "# More examples\n",
    "exs = '\\n\\n'.join([\n",
    "    to_example(train[0]),\n",
    "    to_example(train[10]),\n",
    "    to_example(train[100]),\n",
    "    to_example(train[200]),\n",
    "    to_example(train[300]),\n",
    "    to_example(train[400])\n",
    "])\n",
    "x = to_example(train[4], False)\n",
    "prompt = f'{exs}\\n\\n{x}'\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7874e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-47FaZgENEwPTkI7z0jUUrX6ZbdcFi at 0x7f76c87b1a40> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1637633567,\n",
       "  \"id\": \"cmpl-47FaZgENEwPTkI7z0jUUrX6ZbdcFi\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 max tokens for good measure\n",
    "response = openai.Completion.create(\n",
    "  engine='davinci',\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=10,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=['\\n']\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d40fd4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a textual entailment classifier.\n",
      "\n",
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is training his horse for a competition.\n",
      "label: neutral\n",
      "\n",
      "premise: An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\n",
      "hypothesis: A boy flips a burger.\n",
      "label: contradiction\n",
      "\n",
      "premise: A woman is walking across the street eating a banana, while a man is following with his briefcase.\n",
      "hypothesis: the woman is a seductress\n",
      "label: neutral\n",
      "\n",
      "premise: People on bicycles waiting at an intersection.\n",
      "hypothesis: There is a bike race happening right now.\n",
      "label: neutral\n",
      "\n",
      "premise: A foreign family is walking along a dirt path next to the water.\n",
      "hypothesis: A family of foreigners walks by the water.\n",
      "label: entailment\n",
      "\n",
      "premise: A guy performing a bicycle jump trick for an audience.\n",
      "hypothesis: tony hawk is performing a skating trick\n",
      "label: contradiction\n",
      "\n",
      "premise: Children smiling and waving at camera\n",
      "hypothesis: There are children present\n",
      "label: \n"
     ]
    }
   ],
   "source": [
    "# Perhaps it requires a task description to actually work\n",
    "task = 'This is a textual entailment classifier.'\n",
    "prompt = f'{task}\\n\\n{exs}\\n\\n{x}'\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd8d7796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-47FeEDk0Vp5i0ZPTw1hDAS4XOYfLK at 0x7f76c8765400> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1637633794,\n",
       "  \"id\": \"cmpl-47FeEDk0Vp5i0ZPTw1hDAS4XOYfLK\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine='davinci',\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=10,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=['\\n']\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d806036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a textual entailment classifier that detemines the inference relation between premise and hypothesis with the labels: entailment, contradiction, or neutral.\n",
      "\n",
      "premise: A person on a horse jumps over a broken down airplane.\n",
      "hypothesis: A person is training his horse for a competition.\n",
      "label: neutral\n",
      "\n",
      "premise: An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\n",
      "hypothesis: A boy flips a burger.\n",
      "label: contradiction\n",
      "\n",
      "premise: A woman is walking across the street eating a banana, while a man is following with his briefcase.\n",
      "hypothesis: the woman is a seductress\n",
      "label: neutral\n",
      "\n",
      "premise: People on bicycles waiting at an intersection.\n",
      "hypothesis: There is a bike race happening right now.\n",
      "label: neutral\n",
      "\n",
      "premise: A foreign family is walking along a dirt path next to the water.\n",
      "hypothesis: A family of foreigners walks by the water.\n",
      "label: entailment\n",
      "\n",
      "premise: A guy performing a bicycle jump trick for an audience.\n",
      "hypothesis: tony hawk is performing a skating trick\n",
      "label: contradiction\n",
      "\n",
      "premise: Children smiling and waving at camera\n",
      "hypothesis: There are children present\n",
      "label: \n"
     ]
    }
   ],
   "source": [
    "# More details about the task\n",
    "task = 'This is a textual entailment classifier that detemines the inference relation between premise and hypothesis with the labels: entailment, contradiction, or neutral.'\n",
    "prompt = f'{task}\\n\\n{exs}\\n\\n{x}'\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1e57d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-47FgPVtpFHtcZ6rTdPzTCGM2xEral at 0x7f76c876fea0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1637633929,\n",
       "  \"id\": \"cmpl-47FgPVtpFHtcZ6rTdPzTCGM2xEral\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine='davinci',\n",
    "  prompt=prompt,\n",
    "  max_tokens=100,\n",
    "  stop=['\\n']\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a27a1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still fails to generate a valid text\n",
    "# We can try to get rid of the stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36cd1384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-47FhJVxpHHZZC7AKlkcGRMgDaz4ta at 0x7f76c876c3b0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\npremise: Girls sitting at outdoor tea area talking excitedly, one pointing empty tea cup at each other, another reading tea card.\\nlabel: \\n\\nThere are three strategies for evaluating w-ETT accuracy, knowledge transfer, logical validity, and RPSL compliance. The lack of ground truth in visual reasoning makes evaluation difficult, but since all proposed models derive their inference representation from the premises, they are using the same representations. The major challenge in evaluating w-ETT\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1637633985,\n",
       "  \"id\": \"cmpl-47FhJVxpHHZZC7AKlkcGRMgDaz4ta\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine='davinci',\n",
    "  prompt=prompt,\n",
    "  max_tokens=100,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0223e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically, it never wants to generate a label. It always continue to generate more examples for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e78b0b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "premise: Girls sitting at outdoor tea area talking excitedly, one pointing empty tea cup at each other, another reading tea card.\n",
      "label: \n",
      "\n",
      "There are three strategies for evaluating w-ETT accuracy, knowledge transfer, logical validity, and RPSL compliance. The lack of ground truth in visual reasoning makes evaluation difficult, but since all proposed models derive their inference representation from the premises, they are using the same representations. The major challenge in evaluating w-ETT\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\npremise: Girls sitting at outdoor tea area talking excitedly, one pointing empty tea cup at each other, another reading tea card.\\nlabel: \\n\\nThere are three strategies for evaluating w-ETT accuracy, knowledge transfer, logical validity, and RPSL compliance. The lack of ground truth in visual reasoning makes evaluation difficult, but since all proposed models derive their inference representation from the premises, they are using the same representations. The major challenge in evaluating w-ETT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27f8adce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a tweet sentiment classifier\n",
      "\n",
      "\n",
      "Tweet: \"I loved the new Batman movie!\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"I hate it when my phone battery dies.\"\n",
      "Sentiment: Negative\n",
      "###\n",
      "Tweet: \"My day has been 👍\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"This is the link to the article\"\n",
      "Sentiment: Neutral\n",
      "###\n",
      "Tweet: \"This new music video blew my mind\"\n",
      "Sentiment: \n"
     ]
    }
   ],
   "source": [
    "# The Tweet sentiment classifier from the example\n",
    "prompt = \"\"\"This is a tweet sentiment classifier\n",
    "\n",
    "\n",
    "Tweet: \"I loved the new Batman movie!\"\n",
    "Sentiment: Positive\n",
    "###\n",
    "Tweet: \"I hate it when my phone battery dies.\"\n",
    "Sentiment: Negative\n",
    "###\n",
    "Tweet: \"My day has been 👍\"\n",
    "Sentiment: Positive\n",
    "###\n",
    "Tweet: \"This is the link to the article\"\n",
    "Sentiment: Neutral\n",
    "###\n",
    "Tweet: \"This new music video blew my mind\"\n",
    "Sentiment: \"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c76c82a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a textual entailment classifier.\n",
      "\n",
      "Premise: \"A person on a horse jumps over a broken down airplane.\"\n",
      "Hypothesis: \"A person is training his horse for a competition.\"\n",
      "Label: Neutral\n",
      "###\n",
      "Premise: \"An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\"\n",
      "Hypothesis: \"A boy flips a burger.\"\n",
      "Label: Contradiction\n",
      "###\n",
      "Premise: \"A woman is walking across the street eating a banana, while a man is following with his briefcase.\"\n",
      "Hypothesis: \"the woman is a seductress\"\n",
      "Label: Neutral\n",
      "###\n",
      "Premise: \"People on bicycles waiting at an intersection.\"\n",
      "Hypothesis: \"There is a bike race happening right now.\"\n",
      "Label: Neutral\n",
      "###\n",
      "Premise: \"A foreign family is walking along a dirt path next to the water.\"\n",
      "Hypothesis: \"A family of foreigners walks by the water.\"\n",
      "Label: Entailment\n",
      "###\n",
      "Premise: \"A guy performing a bicycle jump trick for an audience.\"\n",
      "Hypothesis: \"tony hawk is performing a skating trick\"\n",
      "Label: Contradiction\n",
      "###\n",
      "Premise: \"Children smiling and waving at camera\"\n",
      "Hypothesis: \"There are children present\"\n",
      "Label: \n"
     ]
    }
   ],
   "source": [
    "# Let's try to mimick the example\n",
    "def to_example(data, include_label=True):\n",
    "    sentences = []\n",
    "    \n",
    "    for feature in data.keys():                \n",
    "        text = data[feature]\n",
    "        \n",
    "        if feature == 'label':\n",
    "            if not include_label:\n",
    "                text = ''\n",
    "            else:\n",
    "                text = int2label(text).capitalize()\n",
    "        else:\n",
    "            text = f'\"{text}\"'\n",
    "            \n",
    "        sentence = f'{feature.capitalize()}: {text}'\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return '\\n'.join(sentences)\n",
    "\n",
    "exs = '\\n###\\n'.join([\n",
    "    to_example(train[0]),\n",
    "    to_example(train[10]),\n",
    "    to_example(train[100]),\n",
    "    to_example(train[200]),\n",
    "    to_example(train[300]),\n",
    "    to_example(train[400])\n",
    "])\n",
    "x = to_example(train[4], False)\n",
    "\n",
    "task = 'This is a textual entailment classifier.'\n",
    "prompt = f'{task}\\n\\n{exs}\\n###\\n{x}'\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6a75fbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-47FufL86uOqEuAMe9lcIp5UXfDg9r at 0x7f76c934ae00> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1637634813,\n",
       "  \"id\": \"cmpl-47FufL86uOqEuAMe9lcIp5UXfDg9r\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine='davinci',\n",
    "    prompt=prompt,\n",
    "    temperature=0.3,\n",
    "    max_tokens=60,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0,\n",
    "    stop=[\"###\"]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c30deab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
