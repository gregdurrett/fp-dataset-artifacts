{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5b15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fp_dataset_artifacts.utils import init_openai\n",
    "\n",
    "init_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9846f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/x/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaabed435bf64bbf970955600b4aecf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 550152\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
    "\n",
    "data = load_dataset('snli')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5a16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84de8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://beta.openai.com/docs/guides/classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc3656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the train.jsonl file\n",
    "\n",
    "{\"text\": \"good film, but very glum.\", \"label\": \"Positive\", \"metadata\": {\"source\":\"example.com\"}}\n",
    "{\"text\": \"i sympathize with the plight of these families, but the movie doesn't do a very good job conveying the issue at hand.\", \"label\": \"Negative\", \"metadata\": {\"source\":\"example.com\"}}\n",
    "\n",
    "... (more rows)\n",
    "\"\"\"\n",
    "\n",
    "def build_jsonl(data):\n",
    "    import json\n",
    "    \n",
    "    with open('snli_train.jsonl', 'w') as f:\n",
    "        for x in data:\n",
    "            f.write(json.dumps(x) + '\\n') \n",
    "\n",
    "build_jsonl(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43094085",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Expected file to have the JSONL format with 'text' key and (optional) 'metadata' key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6736/1966145709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Upload the examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"snli_train.jsonl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpurpose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"classifications\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/fp-dataset-artifacts-CXlE6369-py3.9/lib/python3.9/site-packages/openai/api_resources/file.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, file, purpose, model, api_key, api_base, api_version, organization)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         return util.convert_to_openai_object(\n\u001b[1;32m     40\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/fp-dataset-artifacts-CXlE6369-py3.9/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         )\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/fp-dataset-artifacts-CXlE6369-py3.9/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             return (\n\u001b[0;32m--> 292\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    293\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 ),\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/fp-dataset-artifacts-CXlE6369-py3.9/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    319\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Expected file to have the JSONL format with 'text' key and (optional) 'metadata' key."
     ]
    }
   ],
   "source": [
    "# Upload the examples\n",
    "openai.File.create(file=open(\"snli_train.jsonl\"), purpose=\"classifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60fff507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'A person is training his horse for a competition.',\n",
       " 'metadata': {'premise': 'A person on a horse jumps over a broken down airplane.'},\n",
       " 'label': 'neutral'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification expects certain format\n",
    "int2label = data['train'].features['label'].int2str\n",
    "\n",
    "def format_jsonl(x):\n",
    "     return {\n",
    "         'text': x['hypothesis'],\n",
    "         'metadata': {'premise': x['premise']},\n",
    "         'label': int2label(x['label'])\n",
    "     }\n",
    "    \n",
    "format_jsonl(data['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46290c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the examples with the correct formatting. Hypothesis is used as the text since it's known for model\n",
    "# to perform pretty well without premises due to dataset artifact.\n",
    "def build_jsonl(data):\n",
    "    import json\n",
    "    \n",
    "    with open('snli_train.jsonl', 'w') as f:\n",
    "        for x in data:\n",
    "            if x['label'] >= 0:\n",
    "                f.write(json.dumps(format_jsonl(x)) + '\\n') \n",
    "\n",
    "build_jsonl(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be413eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-PbSzGW2gSR0pOTYlfiDsgIrf at 0x7f32be57eea0> JSON: {\n",
       "  \"bytes\": 92713950,\n",
       "  \"created_at\": 1638407457,\n",
       "  \"filename\": \"snli_train.jsonl\",\n",
       "  \"id\": \"file-PbSzGW2gSR0pOTYlfiDsgIrf\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"classifications\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.create(file=open(\"snli_train.jsonl\"), purpose=\"classifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5ceb7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'This church choir sings to the masses as they sing joyous songs from the book at a church.',\n",
       " 'hypothesis': 'The church has cracks in the ceiling.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try with a test set\n",
    "data['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2eb1cbc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "File is still processing.  Check back later.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6736/3782354762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m openai.Classification.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"file-PbSzGW2gSR0pOTYlfiDsgIrf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"The church has cracks in the ceiling.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msearch_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ada\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"curie\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/fp-dataset-artifacts-CXlE6369-py3.9/lib/python3.9/site-packages/openai/api_resources/classification.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, **params)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classifications\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/fp-dataset-artifacts-CXlE6369-py3.9/lib/python3.9/site-packages/openai/openai_object.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, stream, plain_old_data, request_id)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morganization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         )\n\u001b[0;32m--> 170\u001b[0;31m         response, stream, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         )\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/fp-dataset-artifacts-CXlE6369-py3.9/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         )\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/fp-dataset-artifacts-CXlE6369-py3.9/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             return (\n\u001b[0;32m--> 292\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    293\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 ),\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/fp-dataset-artifacts-CXlE6369-py3.9/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    319\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: File is still processing.  Check back later."
     ]
    }
   ],
   "source": [
    "openai.Classification.create(\n",
    "    file=\"file-PbSzGW2gSR0pOTYlfiDsgIrf\",\n",
    "    query=\"The church has cracks in the ceiling.\",\n",
    "    search_model=\"ada\", \n",
    "    model=\"curie\", \n",
    "    max_examples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36460162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems to take some time to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d21847c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject classification at 0x7f32be568720> JSON: {\n",
       "  \"completion\": \"cmpl-4AUy9WeoDihb7mRGCFiuWhyV93F0i\",\n",
       "  \"file\": \"file-PbSzGW2gSR0pOTYlfiDsgIrf\",\n",
       "  \"label\": \"Entailment\",\n",
       "  \"model\": \"curie:2020-05-03\",\n",
       "  \"object\": \"classification\",\n",
       "  \"search_model\": \"ada:2020-05-03\",\n",
       "  \"selected_examples\": [\n",
       "    {\n",
       "      \"document\": 1,\n",
       "      \"label\": \"Entailment\",\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 77.784,\n",
       "      \"text\": \"Man paints a ceiling.\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 0,\n",
       "      \"label\": \"Entailment\",\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 58.753,\n",
       "      \"text\": \"The market has a ceiling.\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 2,\n",
       "      \"label\": \"Entailment\",\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 78.084,\n",
       "      \"text\": \"This is a ceiling in a cafeteria.\"\n",
       "    }\n",
       "  ],\n",
       "  \"warnings\": [\n",
       "    {\n",
       "      \"code\": \"wrong_labels\",\n",
       "      \"message\": \"Two class labels should be provided at minimum. Only 1 label is found.\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Classification.create(\n",
    "    file=\"file-PbSzGW2gSR0pOTYlfiDsgIrf\",\n",
    "    query=\"The church has cracks in the ceiling.\",\n",
    "    search_model=\"ada\", \n",
    "    model=\"curie\", \n",
    "    max_examples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0075984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The classification model predicts entailment even though it should be neutral\n",
    "int2label(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f604848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's gather some stats on 100 test data points\n",
    "test = data['test'][:100]\n",
    "texts = test['hypothesis']\n",
    "labels = list(map(lambda x: int2label(x) if x >= 0 else 'neutral', test['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f2919c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use yield instead of return\n",
    "def make_classification(x):\n",
    "    return openai.Classification.create(\n",
    "        file=\"file-PbSzGW2gSR0pOTYlfiDsgIrf\",\n",
    "        query=x,\n",
    "        search_model=\"ada\", \n",
    "        model=\"curie\", \n",
    "        max_examples=3\n",
    "    )\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for text in texts:\n",
    "    results.append(make_classification(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef2245e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Entailment',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Entailment',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Neutral',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Entailment',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Entailment',\n",
       " 'Entailment',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Neutral',\n",
       " 'Contradiction',\n",
       " 'Contradiction',\n",
       " 'Entailment',\n",
       " 'Contradiction',\n",
       " 'Contradiction']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = [x['label'] for x in results]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4060ed4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = [label.capitalize() == output for label, output in zip(labels, outputs)]\n",
    "sum(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c13ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 44% is slightly better than 33%, but it's very low compared to fine-tuned BERT-based models\n",
    "# It's actually surprising that it's getting 44% at all simply based on hypothesis alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ee1593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the outputs\n",
    "\n",
    "def build_jsonl(data):\n",
    "    import json\n",
    "    \n",
    "    with open('snli_preds.jsonl', 'w') as f:\n",
    "        for x in data:\n",
    "            f.write(json.dumps(x) + '\\n')\n",
    "            \n",
    "build_jsonl(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0445c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
