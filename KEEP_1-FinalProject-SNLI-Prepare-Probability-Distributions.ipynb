{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple notebook that transforms the SNLI dev and test datasets to contain probability distributions\n",
    "The probability distribution for each example is just the count of each annotation type (entailment, neutral, or contradiction) divided by the total number of annotations (i.e., 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dist(x):\n",
    "        \n",
    "    al = x.annotator_labels\n",
    "    counter = Counter(al)\n",
    "\n",
    "    num_annotators = len(al)\n",
    "    num_entail = counter['entailment']\n",
    "    num_neutral = counter['neutral']\n",
    "    num_contra = counter['contradiction']\n",
    "    \n",
    "    return [i/num_annotators for i in [num_entail, num_neutral, num_contra]]\n",
    "\n",
    "\n",
    "def gold_to_int(gold):\n",
    "    if gold == 'entailment':\n",
    "        return 0\n",
    "    elif gold == 'neutral':\n",
    "        return 1\n",
    "    elif gold == 'contradiction':\n",
    "        return 2\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_PATH = '../data/snli_1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the `dev` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the original file\n",
    "dev_snli_df = pd.read_json(f'{ROOT_DATA_PATH}/snli_1.0_dev.jsonl', lines=True)\n",
    "\n",
    "# generate the probability distributions\n",
    "dev_snli_df['label'] = dev_snli_df.apply(lambda x: gen_dist(x), axis=1)\n",
    "\n",
    "# generate an integer gold label\n",
    "dev_snli_df['label_g'] = dev_snli_df.apply(lambda x: gold_to_int(x['gold_label']), axis=1)\n",
    "\n",
    "# remove any completely ambiguous examples\n",
    "dev_snli_df = dev_snli_df.query('label_g != -1')\n",
    "dev_snli_df = dev_snli_df.drop(columns=['annotator_labels', 'captionID',\n",
    "                                        'pairID', 'sentence1_binary_parse',\n",
    "                                        'sentence1_parse', 'sentence2_binary_parse',\n",
    "                                        'sentence2_parse'])\n",
    "\n",
    "# rename the premise and hypothesis columns\n",
    "dev_snli_df = dev_snli_df.rename(columns={'sentence1': 'premise', 'sentence2': 'hypothesis'})\n",
    "\n",
    "# write the new data\n",
    "with open(f'{ROOT_DATA_PATH}/snli_1.0_dev_probs.jsonl', 'w') as f:\n",
    "    f.write(dev_snli_df.to_json(orient='records', lines=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the `test` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the original file\n",
    "test_snli_df = pd.read_json(f'{ROOT_DATA_PATH}/snli_1.0_test.jsonl', lines=True)\n",
    "\n",
    "# generate the probability distributions\n",
    "test_snli_df['label'] = test_snli_df.apply(lambda x: gen_dist(x), axis=1)\n",
    "\n",
    "# generate an integer gold label\n",
    "test_snli_df['label_g'] = test_snli_df.apply(lambda x: gold_to_int(x['gold_label']), axis=1)\n",
    "\n",
    "# remove any completely ambiguous examples\n",
    "test_snli_df = test_snli_df.query('label_g != -1')\n",
    "test_snli_df = test_snli_df.drop(columns=['annotator_labels', 'captionID',\n",
    "                                          'pairID', 'sentence1_binary_parse',\n",
    "                                          'sentence1_parse', 'sentence2_binary_parse',\n",
    "                                          'sentence2_parse'])\n",
    "\n",
    "# rename the premise and hypothesis columns\n",
    "test_snli_df = test_snli_df.rename(columns={'sentence1': 'premise', 'sentence2': 'hypothesis'})\n",
    "\n",
    "# write the new data\n",
    "with open(f'{ROOT_DATA_PATH}/snli_1.0_test_probs.jsonl', 'w') as f:\n",
    "    f.write(test_snli_df.to_json(orient='records', lines=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc-395t-nlp-final-project-new",
   "language": "python",
   "name": "dsc-395t-nlp-final-project-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
