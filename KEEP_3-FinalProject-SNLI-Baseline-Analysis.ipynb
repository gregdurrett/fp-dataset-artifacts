{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_OUTPUT_PATH = './output_final/trained_model_snli_baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This comes from the ChaosNLI github repository:\n",
    "# https://github.com/easonnie/ChaosNLI/blob/master/distnli/src/evaluation/tools.py#L24\n",
    "def model_label_dist(logits_list):\n",
    "\n",
    "    logits = np.asarray(logits_list)\n",
    "    prob = np.exp(logits_list) / np.sum(np.exp(logits_list))\n",
    "\n",
    "    # numerical stability for KL\n",
    "    for i, value in enumerate(prob):\n",
    "        if np.abs(value) < 1e-15:\n",
    "            prob[i] = 1e-15\n",
    "    \n",
    "    # normalize\n",
    "    prob = prob / np.sum(prob)\n",
    "    assert np.isclose(np.sum(prob), 1)\n",
    "    \n",
    "    return prob\n",
    "\n",
    "\n",
    "def generate_metrics_dict(df):\n",
    "    \n",
    "    return {'acc': len(df.query('label_g == predicted_label'))/len(df),\n",
    "            'jsd': df.jsd.mean(),\n",
    "            'kld': df.kld.mean()}\n",
    "\n",
    "\n",
    "def generate_all_metrics_dict(df):\n",
    "\n",
    "    return {'all': generate_metrics_dict(df),\n",
    "            'no-ambiguity': generate_metrics_dict(df.query('amb_level == 0')),\n",
    "            'medium-ambiguity': generate_metrics_dict(df.query('amb_level == 1')),\n",
    "            'high-ambiguity': generate_metrics_dict(df.query('amb_level == 2'))}\n",
    "\n",
    "\n",
    "def calculate_example_metrics(df, use_probs = False):\n",
    "\n",
    "    if not use_probs:\n",
    "        df['predicted_probs'] = df.apply(lambda x: model_label_dist(x.predicted_scores), axis=1)\n",
    "        \n",
    "    df['jsd'] = df.apply(lambda x: jensenshannon(x.label, x.predicted_probs), axis=1)\n",
    "    df['kld'] = df.apply(lambda x: entropy(x.label, x.predicted_probs), axis=1)\n",
    "    df['amb_level'] = df.apply(lambda x: get_ambiguity_level(x), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_ambiguity_level(x):\n",
    "\n",
    "    # this whole thing is a bit klugy, but <shrug> it works since there might be some fp imprecision.\n",
    "    label_count = max(x.label)*5\n",
    "\n",
    "    if label_count > 4.5:\n",
    "        return 0\n",
    "    elif label_count > 3.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the baseline predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': {'acc': 0.8890472312703583,\n",
       "  'jsd': 0.19018686160110934,\n",
       "  'kld': 0.42401248721189044},\n",
       " 'no-ambiguity': {'acc': 0.9544101228135468,\n",
       "  'jsd': 0.10453239072285646,\n",
       "  'kld': 0.135539159308617},\n",
       " 'medium-ambiguity': {'acc': 0.8847091605712295,\n",
       "  'jsd': 0.2620504238347566,\n",
       "  'kld': 0.6118892730848189},\n",
       " 'high-ambiguity': {'acc': 0.6744775174160861,\n",
       "  'jsd': 0.35103983140917144,\n",
       "  'kld': 1.0642033750592708}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_json(f'{ROOT_OUTPUT_PATH}/trained_train_gold_dev_gold_evaled_test_probs/eval_predictions.jsonl', lines=True)\n",
    "eval_df = calculate_example_metrics(eval_df)\n",
    "generate_all_metrics_dict(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see that accuracy drops dramatically as the ambiguity level increases. Can "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'all': {'acc': 0.8905741042345277,\n",
    "  'jsd': 0.21167255341506863,\n",
    "  'kld': 0.2573941631956475},\n",
    " 'no-ambiguity': {'acc': 0.9542240416821735,\n",
    "  'jsd': 0.18507676339716447,\n",
    "  'kld': 0.1685656369707211},\n",
    " 'medium-ambiguity': {'acc': 0.8861024033437827,\n",
    "  'jsd': 0.2219503197507553,\n",
    "  'kld': 0.2965972979670458},\n",
    " 'high-ambiguity': {'acc': 0.682077264091197,\n",
    "  'jsd': 0.28350175443245973,\n",
    "  'kld': 0.4884342518619364}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a dataset with a uniform probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': {'acc': 0.8890472312703583,\n",
       "  'jsd': 0.48318590731310385,\n",
       "  'kld': 0.8341626268207454},\n",
       " 'no-ambiguity': {'acc': 0.9544101228135468,\n",
       "  'jsd': 0.5641427870206321,\n",
       "  'kld': 1.0986122886681098},\n",
       " 'medium-ambiguity': {'acc': 0.8847091605712295,\n",
       "  'jsd': 0.41644967095404145,\n",
       "  'kld': 0.5981451496428996},\n",
       " 'high-ambiguity': {'acc': 0.6744775174160861,\n",
       "  'jsd': 0.32899810683090697,\n",
       "  'kld': 0.3632656630524493}}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unif_df = eval_df.assign(predicted_probs = [[1/3, 1/3, 1/3]]*len(eval_df))\n",
    "unif_df = calculate_example_metrics(unif_df, use_probs=True)\n",
    "generate_all_metrics_dict(unif_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at highly ambiguous data (i.e., amb_level == 2) where the Jensen-Shannon divergence is great than the uniform Jensen-Shannon divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(left=eval_df, right=unif_df, left_index=True, right_index=True, suffixes=('', '_unif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = merge_df[['gold_label', 'premise', 'hypothesis', 'label', 'label_g',\n",
    "                     'predicted_label', 'predicted_probs', 'jsd', 'amb_level',\n",
    "                     'predicted_probs_unif', 'jsd_unif']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "amb_and_bad_df = merge_df.query('amb_level == 2 and jsd > jsd_unif')[['label_g', 'predicted_label', 'label', 'predicted_probs', 'jsd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bb433_row0_col0, #T_bb433_row0_col1, #T_bb433_row0_col2, #T_bb433_row0_col3, #T_bb433_row0_col4, #T_bb433_row1_col0, #T_bb433_row1_col1, #T_bb433_row1_col2, #T_bb433_row1_col3, #T_bb433_row1_col4, #T_bb433_row2_col0, #T_bb433_row2_col1, #T_bb433_row2_col2, #T_bb433_row2_col3, #T_bb433_row2_col4, #T_bb433_row3_col0, #T_bb433_row3_col1, #T_bb433_row3_col2, #T_bb433_row3_col3, #T_bb433_row3_col4, #T_bb433_row4_col0, #T_bb433_row4_col1, #T_bb433_row4_col2, #T_bb433_row4_col3, #T_bb433_row4_col4 {\n",
       "  width: 500px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bb433_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >label_g</th>\n",
       "      <th class=\"col_heading level0 col1\" >predicted_label</th>\n",
       "      <th class=\"col_heading level0 col2\" >label</th>\n",
       "      <th class=\"col_heading level0 col3\" >predicted_probs</th>\n",
       "      <th class=\"col_heading level0 col4\" >jsd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bb433_level0_row0\" class=\"row_heading level0 row0\" >4</th>\n",
       "      <td id=\"T_bb433_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_bb433_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_bb433_row0_col2\" class=\"data row0 col2\" >[0.6000000000000001, 0.2, 0.2]</td>\n",
       "      <td id=\"T_bb433_row0_col3\" class=\"data row0 col3\" >[0.86094322 0.1373969  0.00165987]</td>\n",
       "      <td id=\"T_bb433_row0_col4\" class=\"data row0 col4\" >0.282339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb433_level0_row1\" class=\"row_heading level0 row1\" >12</th>\n",
       "      <td id=\"T_bb433_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_bb433_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_bb433_row1_col2\" class=\"data row1 col2\" >[0.6000000000000001, 0.4, 0.0]</td>\n",
       "      <td id=\"T_bb433_row1_col3\" class=\"data row1 col3\" >[0.05213389 0.92668411 0.021182  ]</td>\n",
       "      <td id=\"T_bb433_row1_col4\" class=\"data row1 col4\" >0.442991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb433_level0_row2\" class=\"row_heading level0 row2\" >20</th>\n",
       "      <td id=\"T_bb433_row2_col0\" class=\"data row2 col0\" >1</td>\n",
       "      <td id=\"T_bb433_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "      <td id=\"T_bb433_row2_col2\" class=\"data row2 col2\" >[0.2, 0.6000000000000001, 0.2]</td>\n",
       "      <td id=\"T_bb433_row2_col3\" class=\"data row2 col3\" >[0.36759535 0.62382939 0.00857526]</td>\n",
       "      <td id=\"T_bb433_row2_col4\" class=\"data row2 col4\" >0.258996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb433_level0_row3\" class=\"row_heading level0 row3\" >23</th>\n",
       "      <td id=\"T_bb433_row3_col0\" class=\"data row3 col0\" >1</td>\n",
       "      <td id=\"T_bb433_row3_col1\" class=\"data row3 col1\" >2</td>\n",
       "      <td id=\"T_bb433_row3_col2\" class=\"data row3 col2\" >[0.0, 0.6000000000000001, 0.4]</td>\n",
       "      <td id=\"T_bb433_row3_col3\" class=\"data row3 col3\" >[4.55578389e-04 2.47427617e-02 9.74801660e-01]</td>\n",
       "      <td id=\"T_bb433_row3_col4\" class=\"data row3 col4\" >0.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb433_level0_row4\" class=\"row_heading level0 row4\" >65</th>\n",
       "      <td id=\"T_bb433_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_bb433_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_bb433_row4_col2\" class=\"data row4 col2\" >[0.6000000000000001, 0.2, 0.2]</td>\n",
       "      <td id=\"T_bb433_row4_col3\" class=\"data row4 col3\" >[0.94647857 0.04715054 0.0063709 ]</td>\n",
       "      <td id=\"T_bb433_row4_col4\" class=\"data row4 col4\" >0.319863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7e79ba5790>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amb_and_bad_df.head(5).style.set_properties(**{'width': '500px'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc-395t-nlp-final-project-new",
   "language": "python",
   "name": "dsc-395t-nlp-final-project-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
